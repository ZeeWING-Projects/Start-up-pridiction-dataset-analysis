{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING DATA SET\n",
    "\n",
    "data = pd.read_csv(\"startupdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Couting null values in each column.\n",
    "#print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before filling null values.\n",
    "#print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values.\n",
    "#Now filling the null values.\n",
    "def imputing_numeric_missing_values(dataset,n_neighbors=10):\n",
    "    numerical_column_names = dataset.select_dtypes([np.number]).columns\n",
    "    knn= KNNImputer()\n",
    "    knn_dataset= knn.fit_transform(dataset[numerical_column_names])\n",
    "    \n",
    "    dataset[numerical_column_names]=pd.DataFrame(knn_dataset)\n",
    "    return dataset\n",
    "\n",
    "data=imputing_numeric_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fillingout null values.\n",
    "#print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the remaining null values.\n",
    "#But before that we need to rename Unnamed: 6   to Unnamed_6  and state_code.1 to state_code_1 \n",
    "data =  data.rename(columns={\"Unnamed: 6\": \"Unnamed_6\",\"state_code.1\":\"state_code_1\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"state_code_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = data.Unnamed_6.value_counts(normalize=True)\n",
    "nan_Unnamed_6 = data['Unnamed_6'].isnull()\n",
    "data.loc[nan_Unnamed_6,'Unnamed_6'] = np.random.choice(dist.index, size=len(data[nan_Unnamed_6]),p=dist.values)\n",
    "\n",
    "dist = data.closed_at.value_counts(normalize=True)\n",
    "nan_closed_at = data['closed_at'].isnull()\n",
    "data.loc[nan_closed_at,'closed_at'] = np.random.choice(dist.index, size=len(data[nan_closed_at]),p=dist.values)\n",
    "\n",
    "dist = data.state_code_1.value_counts(normalize=True)\n",
    "nan_state_code_1 = data['state_code_1'].isnull()\n",
    "data.loc[nan_state_code_1,'state_code_1'] = np.random.choice(dist.index, size=len(data[nan_state_code_1]),p=dist.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fillingout null values.\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting string values to numeric form.\n",
    "# here we convert the string based columns into integer or in numeric form.\n",
    "#Converting to feature name\n",
    "# state_code\n",
    "# zip_code\n",
    "# id\n",
    "# city\n",
    "# Unnamed_6\n",
    "# name\n",
    "# founded_at\n",
    "# closed_at\n",
    "# first_funding_at\n",
    "# last_funding_at\n",
    "# state_code_1\n",
    "# category_code\n",
    "# object_id\n",
    "# status\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "enc = LabelEncoder()   \n",
    "\n",
    "enc.fit(data['state_code']) \n",
    "data[\"state_code\"] = ord_enc.fit_transform(data[[\"state_code\"]])\n",
    "\n",
    "enc.fit(data['zip_code']) \n",
    "data[\"zip_code\"] = ord_enc.fit_transform(data[[\"zip_code\"]])\n",
    "\n",
    "enc.fit(data['id']) \n",
    "data[\"id\"] = ord_enc.fit_transform(data[[\"id\"]])\n",
    "\n",
    "\n",
    "enc.fit(data['city']) \n",
    "data[\"city\"] = ord_enc.fit_transform(data[[\"city\"]])\n",
    "\n",
    "enc.fit(data['Unnamed_6']) \n",
    "data[\"Unnamed_6\"] = ord_enc.fit_transform(data[[\"Unnamed_6\"]])\n",
    "\n",
    "enc.fit(data['founded_at']) \n",
    "data[\"founded_at\"] = ord_enc.fit_transform(data[[\"founded_at\"]])\n",
    "\n",
    "enc.fit(data['closed_at']) \n",
    "data[\"closed_at\"] = ord_enc.fit_transform(data[[\"closed_at\"]])\n",
    "\n",
    "enc.fit(data['first_funding_at']) \n",
    "data[\"first_funding_at\"] = ord_enc.fit_transform(data[[\"first_funding_at\"]])\n",
    "\n",
    "enc.fit(data['last_funding_at']) \n",
    "data[\"last_funding_at\"] = ord_enc.fit_transform(data[[\"last_funding_at\"]])\n",
    "\n",
    "enc.fit(data['object_id']) \n",
    "data[\"object_id\"] = ord_enc.fit_transform(data[[\"object_id\"]])\n",
    "\n",
    "to_drop = ['state_code_1']\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "enc.fit(data['name']) \n",
    "data[\"name\"] = ord_enc.fit_transform(data[[\"name\"]])\n",
    "\n",
    "\n",
    "enc.fit(data['category_code']) \n",
    "data[\"category_code\"] = ord_enc.fit_transform(data[[\"category_code\"]])\n",
    "\n",
    "\n",
    "#Now we will convert the status to binary value.\n",
    "# 1. Binarizing the class names.\n",
    "diag_map = {'acquired':1, 'closed':0}\n",
    "data['status'] = data['status'].map(diag_map)\n",
    "# 1.1 chaging the name of colums status to : is_aquired\n",
    "data.rename(columns={'status':'is_acquired'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now standarizing some specific columns.\n",
    "#Since we have decided to keep is_acquired as out class label column. \n",
    "#for classification purposed. So except this \n",
    "#and columns which are showing labels or behaving like\n",
    "#categorical data we will not convert them.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# data[['age_first_funding_year', 'age_last_funding_year','age_first_milestone_year',\n",
    "#       'age_last_milestone_year']] = min_max_scaler.fit_transform(data[['age_first_funding_year', 'age_last_funding_year','age_first_milestone_year',\n",
    "#       'age_last_milestone_year']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_first_funding_year</th>\n",
       "      <th>age_last_funding_year</th>\n",
       "      <th>age_first_milestone_year</th>\n",
       "      <th>age_last_milestone_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.2493</td>\n",
       "      <td>3.0027</td>\n",
       "      <td>4.6685</td>\n",
       "      <td>6.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1260</td>\n",
       "      <td>9.9973</td>\n",
       "      <td>7.0055</td>\n",
       "      <td>7.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0329</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>1.4575</td>\n",
       "      <td>2.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1315</td>\n",
       "      <td>5.3151</td>\n",
       "      <td>6.0027</td>\n",
       "      <td>6.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6685</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>4.5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>7.2521</td>\n",
       "      <td>9.2274</td>\n",
       "      <td>6.0027</td>\n",
       "      <td>6.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>8.4959</td>\n",
       "      <td>8.4959</td>\n",
       "      <td>9.0055</td>\n",
       "      <td>9.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>0.7589</td>\n",
       "      <td>2.8329</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>3.8356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>3.1205</td>\n",
       "      <td>3.1205</td>\n",
       "      <td>4.0027</td>\n",
       "      <td>4.0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_first_funding_year  age_last_funding_year  age_first_milestone_year  \\\n",
       "0                    2.2493                 3.0027                    4.6685   \n",
       "1                    5.1260                 9.9973                    7.0055   \n",
       "2                    1.0329                 1.0329                    1.4575   \n",
       "3                    3.1315                 5.3151                    6.0027   \n",
       "4                    0.0000                 1.6685                    0.0384   \n",
       "..                      ...                    ...                       ...   \n",
       "918                  0.5178                 0.5178                    0.5808   \n",
       "919                  7.2521                 9.2274                    6.0027   \n",
       "920                  8.4959                 8.4959                    9.0055   \n",
       "921                  0.7589                 2.8329                    0.7589   \n",
       "922                  3.1205                 3.1205                    4.0027   \n",
       "\n",
       "     age_last_milestone_year  \n",
       "0                     6.7041  \n",
       "1                     7.0055  \n",
       "2                     2.2055  \n",
       "3                     6.0027  \n",
       "4                     0.0384  \n",
       "..                       ...  \n",
       "918                   4.5260  \n",
       "919                   6.0027  \n",
       "920                   9.0055  \n",
       "921                   3.8356  \n",
       "922                   4.0027  \n",
       "\n",
       "[923 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['age_first_funding_year', 'age_last_funding_year','age_first_milestone_year',\n",
    "        'age_last_milestone_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now making selection of attrbutes from dataset.\n",
    "#So we have two reasons to drop a column from dataset. Either that is un necessary like it may be the id of some column and \n",
    "#other reason can be that there exist some other columns which are highly co-related to it, due to that we can remove all \n",
    "#and can keep only one column.\n",
    "#So first of all we need to see that co-relation graph.\n",
    "\n",
    "# Now ploting the graph\n",
    "def draw_heatmap(dataset):\n",
    "    \n",
    "    \n",
    "    f, ax = plt.subplots(figsize = (18, 18))\n",
    "    \n",
    "    corrMatt = dataset.corr(method='spearman')\n",
    "    \n",
    "    sns.heatmap(corrMatt, annot = True, linewidth = 0.5, fmt = '.1f', ax = ax)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    \n",
    "numerical_df_1=data.select_dtypes(numerics)\n",
    "numerical_column_names = data.select_dtypes(numerics).columns\n",
    "\n",
    "# draw_heatmap(numerical_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we have summed that for strong relation threshold is 0.7>= so we have will have few columns which need to be remove due to strong relation. Following will be removed.\n",
    "\n",
    "# o\tSee there is strong co-relation between age_first_funding_year and last_funding_year so we need to remove either of them. I am removing  first_funding_year.\n",
    "\n",
    "# o\tSee there is strong co-relation between longitude and is_CA so we need to remove either of them. I am removing  longitude. \n",
    "\n",
    "# o\tSee there is strong co-relation between age_first_milestone_year and age_last_milestone_ so we need to remove either of them. I am choosing age_last_milestone_\n",
    "\n",
    "# and we will drop the all keys columns aswell.\n",
    "# 1.\tUnnamed: 0\n",
    "# 2.\tUnnamed: 6\n",
    "# 3.\tid\n",
    "# 4.\tobject_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "to_drop = ['longitude','Unnamed: 0','Unnamed_6','id',\"object_id\"]\n",
    "data.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redarwing after deletion of attrbutes.\n",
    "numerical_df_1=data.select_dtypes(numerics)\n",
    "numerical_column_names = data.select_dtypes(numerics).columns\n",
    "\n",
    "# draw_heatmap(numerical_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>founded_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>first_funding_at</th>\n",
       "      <th>last_funding_at</th>\n",
       "      <th>...</th>\n",
       "      <th>is_othercategory</th>\n",
       "      <th>has_VC</th>\n",
       "      <th>has_angel</th>\n",
       "      <th>has_roundA</th>\n",
       "      <th>has_roundB</th>\n",
       "      <th>has_roundC</th>\n",
       "      <th>has_roundD</th>\n",
       "      <th>avg_participants</th>\n",
       "      <th>is_top500</th>\n",
       "      <th>is_acquired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>42.358880</td>\n",
       "      <td>250.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>37.238916</td>\n",
       "      <td>336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.901049</td>\n",
       "      <td>251.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>37.320309</td>\n",
       "      <td>333.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>37.779281</td>\n",
       "      <td>295.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code   latitude  zip_code   city   name  labels  founded_at  \\\n",
       "0         2.0  42.358880     250.0  173.0   75.0     1.0        15.0   \n",
       "1         2.0  37.238916     336.0  108.0  781.0     1.0         8.0   \n",
       "2         2.0  32.901049     251.0  173.0  585.0     1.0       106.0   \n",
       "3         2.0  37.320309     333.0   55.0  712.0     1.0        10.0   \n",
       "4         2.0  37.779281     295.0  174.0  351.0     0.0       183.0   \n",
       "\n",
       "   closed_at  first_funding_at  last_funding_at  ...  is_othercategory  \\\n",
       "0       80.0             295.0              7.0  ...               1.0   \n",
       "1        5.0             216.0            205.0  ...               0.0   \n",
       "2      112.0             278.0            322.0  ...               0.0   \n",
       "3        7.0             218.0            379.0  ...               0.0   \n",
       "4       24.0             490.0            340.0  ...               0.0   \n",
       "\n",
       "   has_VC  has_angel  has_roundA  has_roundB  has_roundC  has_roundD  \\\n",
       "0     0.0        1.0         0.0         0.0         0.0         0.0   \n",
       "1     1.0        0.0         0.0         1.0         1.0         1.0   \n",
       "2     0.0        0.0         1.0         0.0         0.0         0.0   \n",
       "3     0.0        0.0         0.0         1.0         1.0         1.0   \n",
       "4     1.0        1.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   avg_participants  is_top500  is_acquired  \n",
       "0            1.0000        0.0            1  \n",
       "1            4.7500        1.0            1  \n",
       "2            4.0000        1.0            1  \n",
       "3            3.3333        1.0            1  \n",
       "4            1.0000        1.0            0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Now we will again remove \n",
    "    # •\tlabels\n",
    "    # •\tstate_code\n",
    "    # •\tis_CA\n",
    "\n",
    "to_drop = ['labels','state_code',\"is_CA\"]\n",
    "data.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Redarwing after deletion of attrbutes.\n",
    "numerical_df_1=data.select_dtypes(numerics)\n",
    "numerical_column_names = data.select_dtypes(numerics).columns\n",
    "\n",
    "# draw_heatmap(numerical_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[['age_first_funding_year', 'age_last_funding_year','age_first_milestone_year',\n",
    "#         'age_last_milestone_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop = ['age_last_milestone_year',]\n",
    "# data.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redarwing after deletion of attrbutes.\n",
    "numerical_df_1=data.select_dtypes(numerics)\n",
    "numerical_column_names = data.select_dtypes(numerics).columns\n",
    "\n",
    "# draw_heatmap(numerical_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the CSV file\n",
    "# data.to_csv ('Dataset_02_standarized_.csv', index = False, header=True)\n",
    "data.to_csv ('Dataset_02_non_standarized_.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
